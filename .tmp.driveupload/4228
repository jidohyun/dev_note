
> ìë™í™”ëœ í”„ë¡œê·¸ë¨(ì›¹ í¬ë¡¤ëŸ¬, ìŠ¤íŒŒì´ë”, ë´‡)**ì„ ì´ìš©í•´ ì¸í„°ë„·ìƒì˜ ì›¹ í˜ì´ì§€ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ íƒìƒ‰í•˜ê³ , ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ìƒ‰ì¸í™”í•˜ëŠ” ê³¼ì •

### ì£¼ìš” ì‘ë™ ë°©ì‹

1. **ì‹œì‘**: ì›¹ í¬ë¡¤ëŸ¬ëŠ” ë¯¸ë¦¬ ì •í•´ì§„ URL ëª©ë¡(ì‹œë“œ)ì—ì„œ íƒìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.
2. **íƒìƒ‰**: ì›¹ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ë©´, í˜ì´ì§€ ì•ˆì˜ í•˜ì´í¼ë§í¬ë¥¼ ë°œê²¬í•˜ê³  ì´ë¥¼ ë”°ë¼ ê³„ì†í•´ì„œ ìƒˆë¡œìš´ í˜ì´ì§€ë¥¼ ì°¾ì•„ë‹¤ë‹™ë‹ˆë‹¤.
3. **ìˆ˜ì§‘**: ë°œê²¬í•œ í˜ì´ì§€ì˜ HTML ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
4. **ë°˜ë³µ**: ì´ ê³¼ì •ì„ ëŠì„ì—†ì´ ë°˜ë³µí•˜ë©° ì›¹ìƒì˜ ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.


# ğŸ Colab ì‹¤ìŠµ: Python ì›¹ í¬ë¡¤ë§ (requests + bs4 + csv) ì •ë¦¬

## ğŸš€ ê°œìš”

- **ğŸ¯ ëª©í‘œ:** ì›¹ í˜ì´ì§€ HTMLì„ ê°€ì ¸ì™€ íŒŒì‹±í•˜ê³ , íŠ¹ì • ìš”ì†Œë¥¼ ì¶”ì¶œí•´ ì½˜ì†” ì¶œë ¥ ë° CSVë¡œ ì €ì¥
    
- **ğŸ“š ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬:** `requests`, `bs4(BeautifulSoup)`, `csv`
    
- **ğŸ” ì‹¤ìŠµ ëŒ€ìƒ:** Papago ë©”ì¸ í˜ì´ì§€ HTML, YES24 ì¼ê°„ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì±… ì œëª© í¬ë¡¤ë§
    

---

## ğŸ› ï¸ í™˜ê²½ ì¤€ë¹„

- **Python ë²„ì „:** Colab ê¸°ë³¸ Python
    
- **ì„¤ì¹˜/ì„í¬íŠ¸:**
    
    - `requests`: HTTP ìš”ì²­
    - `bs4`: HTML íŒŒì‹±
    - `csv`: ë°ì´í„° íŒŒì¼ ì €ì¥
        

---

## 1. `requests` ê¸°ë³¸ ì‚¬ìš©ë²•

> ğŸ’¡ **í•µì‹¬ í¬ì¸íŠ¸**
> 
> - `requests.get(url, headers=â€¦, timeout=â€¦)`ë¡œ HTTP GET ìš”ì²­
> - `status_code` í™•ì¸í•˜ì—¬ ì„±ê³µ ì—¬ë¶€ íŒë‹¨ (e.g., `200`)
> - `User-Agent` í—¤ë”ë¡œ ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ê²Œ ì„¤ì •

### ğŸ ì˜ˆì‹œ ì½”ë“œ


```Python
import requests

url = "https://www.example.com"
headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36"
}

resp = requests.get(url, headers=headers, timeout=10)

print(resp.status_code)   # 200ì´ë©´ ì„±ê³µ
print(resp.text[:500])    # ì‘ë‹µ HTML ì¼ë¶€ ë¯¸ë¦¬ë³´ê¸°
```

> âš ï¸ **ìœ ì˜ì‚¬í•­**
> 
> - `timeout`ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
> - ì„œë¹„ìŠ¤ ì •ì±…(TOS) ì¤€ìˆ˜, ê³µê²©ì  í¬ë¡¤ë§ ê¸ˆì§€
> - ê³¼ë„í•œ ë¹ˆë„ ìš”ì²­ì€ ì°¨ë‹¨ ìœ„í—˜

---

## 2. `BeautifulSoup` (bs4)ë¡œ HTML íŒŒì‹±

> ğŸ’¡ **í•µì‹¬ í¬ì¸íŠ¸**
> 
> - `BeautifulSoup(html, â€˜html.parserâ€™ ë˜ëŠ” â€˜lxmlâ€™)`
>     
> - CSS ì„ íƒì `select()`, ë‹¨ì¼ ìš”ì†Œ `select_one()`
>     
> - í…ìŠ¤íŠ¸ëŠ” `get_text(strip=True)`
>     

### ğŸ ì˜ˆì‹œ 1: Papago ë©”ì¸ HTML ê°€ì ¸ì˜¤ê¸°

Python

```
import requests
from bs4 import BeautifulSoup

url = "https://papago.naver.com"
resp = requests.get(url)
soup = BeautifulSoup(resp.text, 'html.parser')

print(soup.title.get_text())    # í˜ì´ì§€ ì œëª©
print(soup.find('div', id='root')) # íŠ¹ì • idì˜ ìš”ì†Œ
```

### ğŸ ì˜ˆì‹œ 2: YES24 ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì œëª© ì¶”ì¶œ

Python

```
import requests
from bs4 import BeautifulSoup

url = "https://www.yes24.com/product/category/daybestseller?categoryNumber=001&pageNumber=1&pageSize=24&type=day"
headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36"
}

resp = requests.get(url, headers=headers)
if resp.status_code == requests.codes.ok:
    soup = BeautifulSoup(resp.text, 'lxml')  # ë¹ ë¥´ê³  ì—„ê²©í•œ íŒŒì„œ
    names = soup.select("#yesBestList a.gd_name")  # CSS ì„ íƒìë¡œ ì±… ì œëª© ë§í¬ ì„ íƒ
    for i, name in enumerate(names, 1):
        print(f"{i}ìœ„: {name.get_text(strip=True)}")
else:
    print("ìš”ì²­ ì‹¤íŒ¨:", resp.status_code)
```

### ğŸ“Œ bs4 í…ìŠ¤íŠ¸ ì²˜ë¦¬ íŒ

- `get_text(separator=â€ â€œ, strip=True)`: ìì‹ í…ìŠ¤íŠ¸ë¥¼ ê³µë°±ìœ¼ë¡œ í•©ì¹˜ê³  ì•ë’¤ ê³µë°± ì œê±°
    
- `.text`ëŠ” ë‹¨ìˆœ ë¬¸ìì—´, `.get_text()`ëŠ” ì˜µì…˜ ì œê³µ
    

---

## 3. CSVë¡œ ì €ì¥í•˜ê¸°

> ğŸ’¡ **í•µì‹¬ í¬ì¸íŠ¸**
> 
> - `csv.writer`ë¡œ í–‰ ë‹¨ìœ„ ê¸°ë¡
>     
> - `newline=''`ê³¼ `encoding='utf-8'` í•„ìˆ˜ë¡œ ê¹¨ì§/ì¤„ë°”ê¿ˆ ë¬¸ì œ ì˜ˆë°©
>     

### ğŸ ì˜ˆì‹œ 1: ì„ì‹œ ë°ì´í„° CSV ì €ì¥

Python

```
import csv

csv_path = "output.csv"

with open(csv_path, 'w', newline='', encoding='utf-8') as csvFile:
    writer = csv.writer(csvFile)
    writer.writerow(['First', 'Second', 'Third'])
    writer.writerow(['jwa', 30, 100])

print("CSV ì €ì¥ ì™„ë£Œ:", csv_path)
```

### ğŸ ì˜ˆì‹œ 2: YES24 ë² ìŠ¤íŠ¸ì…€ëŸ¬ë¥¼ CSVë¡œ ì €ì¥

Python

```
import requests
from bs4 import BeautifulSoup
import csv

url = "https://www.yes24.com/product/category/daybestseller?categoryNumber=001&pageNumber=1&pageSize=24&type=day"
headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36"
}

resp = requests.get(url, headers=headers, timeout=10)
resp.raise_for_status()  # ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ

soup = BeautifulSoup(resp.text, 'lxml')
names = soup.select("#yesBestList a.gd_name")

rows = []
for i, name in enumerate(names, 1):
    title = name.get_text(strip=True)
    rows.append([i, title])

csv_path = "yes24_bestsellers.csv"
with open(csv_path, 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(["rank", "title"])
    writer.writerows(rows)

print(f"ì €ì¥ ì™„ë£Œ: {csv_path} (ì´ {len(rows)}ê¶Œ)")
```

---

## 4. ì—ëŸ¬ / ì—£ì§€ ì¼€ì´ìŠ¤ ëŒ€ì‘

- **ìƒíƒœ ì½”ë“œê°€ 200ì´ ì•„ë‹Œ ê²½ìš°:** `resp.raise_for_status()` ë˜ëŠ” ì¡°ê±´ë¬¸ìœ¼ë¡œ ì²˜ë¦¬
    
- **êµ¬ì¡° ë³€ê²½ ê°ì§€:** ì„ íƒì(`select`)ê°€ ë¹ˆ ê²°ê³¼ë©´ ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë°”ë€ ê²ƒì¼ ìˆ˜ ìˆìŒ
    
    - **í•´ê²°:** ê°œë°œì ë„êµ¬ë¡œ ìµœì‹  CSS ì„ íƒì í™•ì¸ í›„ ì—…ë°ì´íŠ¸
        
- **í•œê¸€/ì¸ì½”ë”© ë¬¸ì œ:** `encoding='utf-8'`ë¡œ íŒŒì¼ ì €ì¥, í˜ì´ì§€ ì‘ë‹µì˜ `.encoding` í™•ì¸
    
- **ì°¨ë‹¨/ë´‡ ê°ì§€:** `User-Agent` ì¡°ì •, ìš”ì²­ ê°„ ë”œë ˆì´ ì¶”ê°€, ê³¼ë„í•œ ë³‘ë ¬ ìš”ì²­ í”¼í•˜ê¸°
    

---

## âœ… ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `User-Agent` í—¤ë” ì„¤ì •
    
- [ ] `timeout` ì§€ì •
    
- [ ] ì˜ˆì™¸ ì²˜ë¦¬ (`resp.raise_for_status()`)
    
- [ ] íŒŒì„œ ì„ íƒ: `lxml` ê¶Œì¥ (ì„¤ì¹˜ í•„ìš” ì‹œ `!pip install lxml`)
    
- [ ] ë°ì´í„° ì •ì œ: `get_text(strip=True)` ì‚¬ìš©
    
- [ ] íŒŒì¼ ì…ì¶œë ¥: `newline=â€™â€™`, `encoding=â€˜utf-8â€™`
    
- [ ] ì‚¬ì´íŠ¸ ì´ìš©ì•½ê´€ ë° ë¡œë´‡ ì •ì±…(robots.txt) ì¤€ìˆ˜
    

---

## ğŸ§© ì „ì²´ ì›Œí¬í”Œë¡œìš° í†µí•© ì˜ˆì œ

**ëª©ì :** YES24 ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìˆ˜ì§‘ â†’ ì½˜ì†” ì¶œë ¥ â†’ CSV ì €ì¥

Python

```
import requests
from bs4 import BeautifulSoup
import csv
import time

URL = "https://www.yes24.com/product/category/daybestseller?categoryNumber=001&pageNumber=1&pageSize=24&type=day"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7"
}
CSV_PATH = "yes24_bestsellers.csv"

def fetch_html(url: str) -> str:
    """ì§€ì •ëœ URLì˜ HTMLì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    resp = requests.get(url, headers=HEADERS, timeout=10)
    resp.raise_for_status() # ìš”ì²­ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
    return resp.text

def parse_titles(html: str) -> list[list]:
    """HTMLì„ íŒŒì‹±í•˜ì—¬ [ìˆœìœ„, ì œëª©] ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    soup = BeautifulSoup(html, 'lxml')
    names = soup.select("#yesBestList a.gd_name")
    rows = []
    for i, name in enumerate(names, 1):
        title = name.get_text(strip=True)
        rows.append([i, title])
    return rows

def save_csv(rows: list[list], path: str) -> None:
    """ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(["rank", "title"])
        writer.writerows(rows)

def main():
    try:
        html = fetch_html(URL)
        rows = parse_titles(html)
        
        if not rows:
            print("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return

        print("--- YES24 ë² ìŠ¤íŠ¸ì…€ëŸ¬ ---")
        for r in rows:
            print(f"{r[0]}ìœ„: {r[1]}")
        
        save_csv(rows, CSV_PATH)
        print(f"\nâœ… ì™„ë£Œ: {CSV_PATH}, ì´ {len(rows)}ê¶Œ")

    except requests.exceptions.RequestException as e:
        print(f"HTTP ìš”ì²­ ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
```

---

## ğŸš€ ë‹¤ìŒ í™•ì¥ ì•„ì´ë””ì–´

- í˜ì´ì§€ë„¤ì´ì…˜ ìë™ ë°˜ë³µ ìˆ˜ì§‘ (`pageNumber` ì¦ê°€)
    
- ìƒì„¸ í˜ì´ì§€ë¡œ ë“¤ì–´ê°€ ì €ì/ì¶œíŒì‚¬/ê°€ê²©ê¹Œì§€ í¬ë¡¤ë§
    
- ë°ì´í„°í”„ë ˆì„(pandas)ë¡œ ë³€í™˜ í›„ ì •ë ¬/í•„í„°ë§
    
- ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ ì£¼ê¸°ì  ìˆ˜ì§‘ ë° Google Sheets ì—…ë¡œë“œ